# -*- coding: utf-8 -*-
"""ArtClassification_PretrainedModel.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1PDYGanqBS4pgNBt_1ufLPtksdagOxN1M
"""

# Commented out IPython magic to ensure Python compatibility.
from __future__ import absolute_import, division, print_function, unicode_literals

try:
#   %tensorflow_version 2.x
except Exception:
  pass

import tensorflow as tf
import keras

from tensorflow.keras.models import Sequential

from tensorflow.keras.layers import Dense, Conv2D, Flatten, Dropout, MaxPooling2D
from tensorflow.keras.preprocessing.image import ImageDataGenerator

from keras.preprocessing.image import array_to_img, img_to_array, load_img

import os, shutil
import numpy as np
import matplotlib.pyplot as plt

print(tf.__version__)

from keras.applications import VGG16

conv_base = VGG16(weights='imagenet', include_top = False, input_shape=(200, 200, 3))

conv_base.summary()

import zipfile

from google.colab import drive
drive.mount('/content/gdrive')

import zipfile
import pathlib

#root_directory = pathlib.Path('/content/gdrive/My Drive/testcase1')
root_directory = pathlib.Path('/content/gdrive/My Drive/testcase2')
#root_directory = pathlib.Path('/content/gdrive/My Drive/testcase3')
#root_directory = pathlib.Path('/content/gdrive/My Drive/testcase4')

print(root_directory)

train_dir = pathlib.Path(root_directory, 'train1') 
print(train_dir)
test_dir = pathlib.Path(root_directory, 'test1')
print(test_dir)

train_image_count = len(list(train_dir.glob('*/*.jpg')))
print(train_image_count)
test_image_count = len(list(test_dir.glob('*/*.jpg')))
print(test_image_count)

!ls "/content/gdrive/My Drive/testcase4"

!ls "./sample_data"

"""Create Validation data directory"""

validation_dir = os.path.join(root_directory, 'validation')
#os.mkdir(validation_dir)

valid_abstracticism_dir = os.path.join(validation_dir, 'abstracticism')
#os.mkdir(valid_abstracticism_dir)

valid_baroque_dir = os.path.join(validation_dir, 'baroque')
#os.mkdir(valid_baroque_dir)

valid_impressionism_dir = os.path.join(validation_dir, 'impressionism')
#os.mkdir(valid_impressionism_dir)

valid_minimalism_dir = os.path.join(validation_dir, 'minimalism')
#os.mkdir(valid_minimalism_dir)

valid_popart_dir = os.path.join(validation_dir, 'popart')
#os.mkdir(valid_popart_dir)

!ls "/content/gdrive/My Drive/testcase4/validation"

train_abstracticism_dir = pathlib.Path(train_dir, 'abstracticism')
print(train_abstracticism_dir)
test_abstracticism_dir = pathlib.Path(test_dir, 'abstracticism')
print(test_abstracticism_dir)

train_baroque_dir = pathlib.Path(train_dir, 'baroque')
print(train_baroque_dir)
test_baroque_dir = pathlib.Path(test_dir, 'baroque')
print(test_baroque_dir)

train_impressionism_dir = os.path.join(train_dir, 'impressionism')
print(train_impressionism_dir)
test_impressionism_dir = os.path.join(test_dir, 'impressionism')
print(test_impressionism_dir)

train_minimalism_dir = os.path.join(train_dir, 'minimalism')
print(train_minimalism_dir)
test_minimalism_dir = os.path.join(test_dir, 'minimalism')
print(test_minimalism_dir)

train_popart_dir = pathlib.Path(train_dir, 'popart')
print(train_popart_dir)
test_popart_dir = pathlib.Path(test_dir, 'popart')
print(test_popart_dir)

"""Create validation dataset by extracting from train dataset"""

'''
fnames = ['abstracticism.{}.jpg'.format(i) for i in range(1, 100, 5)]
for fname in fnames:
  src = os.path.join(train_abstracticism_dir, fname)
  dst = os.path.join(valid_abstracticism_dir, fname)
  shutil.move(src, dst)


fnames = ['baroque.{}.jpg'.format(i) for i in range(1, 100, 5)]
for fname in fnames:
  src = os.path.join(train_baroque_dir, fname)
  dst = os.path.join(valid_baroque_dir, fname)
  shutil.move(src, dst)

fnames = ['impressionism.{}.jpg'.format(i) for i in range(101, 200, 5)]
for fname in fnames:
  src = os.path.join(train_impressionism_dir, fname)
  dst = os.path.join(valid_impressionism_dir, fname)
  shutil.move(src, dst)

fnames = ['minimalism.{}.jpg'.format(i) for i in range(1, 100, 5)]
for fname in fnames:
  src = os.path.join(train_minimalism_dir, fname)
  dst = os.path.join(valid_minimalism_dir, fname)
  shutil.move(src, dst)

fnames = ['popart.{}.jpg'.format(i) for i in range(1, 100, 5)]
for fname in fnames:
  src = os.path.join(train_popart_dir, fname)
  dst = os.path.join(valid_popart_dir, fname)
  shutil.move(src, dst)
'''

CLASS_NAMES = np.array([item.name for item in test_dir.glob('*') if item.name != "LICENSE.txt"])
print(CLASS_NAMES)

CLASSES_NAMES = ['abstracticism', 'baroque', 'impressionism', 'minimalism', 'popart']
print(CLASSES_NAMES)

num_abstracticism_tr = len(os.listdir(train_abstracticism_dir))
print('train abstracticism num:', num_abstracticism_tr) 
num_abstracticism_vd = len(os.listdir(valid_abstracticism_dir))
print('validation abstracticism num: ', num_abstracticism_vd)
num_abstracticism_tt = len(os.listdir(test_abstracticism_dir))
print('test abstracticism num: ', num_abstracticism_tt)

num_baroque_tr = len(os.listdir(train_baroque_dir))
print('train baroque num: ', num_baroque_tr)
num_baroque_vd = len(os.listdir(valid_baroque_dir))
print('validation baroque num: ', num_baroque_vd)
num_baroque_tt = len(os.listdir(test_baroque_dir))
print('test baroque num: ', num_baroque_tt)

num_impressionism_tr = len(os.listdir(train_impressionism_dir))
print('train impressionism num: ', num_impressionism_tr)
num_impressionism_vd = len(os.listdir(valid_impressionism_dir))
print('validation impressnionsim num: ', num_impressionism_vd)
num_impressionism_tt = len(os.listdir(test_impressionism_dir))
print('test impressionism num: ', num_impressionism_tt)

num_minimalism_tr = len(os.listdir(train_minimalism_dir))
print('train minimalism num: ', num_minimalism_tr)
num_minimalism_vd = len(os.listdir(valid_minimalism_dir))
print('validation minimalism num: ', num_minimalism_vd)
num_minimalism_tt = len(os.listdir(test_minimalism_dir))
print('test minimalism num: ', num_minimalism_tt)

num_popart_tr = len(os.listdir(train_popart_dir))
print('train popart num: ', num_popart_tr)
num_popart_vd = len(os.listdir(valid_popart_dir))
print('validation popart num: ', num_popart_vd)
num_popart_tt = len(os.listdir(test_popart_dir))
print('test popart num: ', num_popart_tt)

print('------------------------------------------')
total_train = num_abstracticism_tr + num_baroque_tr + num_impressionism_tr + num_minimalism_tr + num_popart_tr
total_valid = num_abstracticism_vd + num_baroque_vd + num_impressionism_vd + num_minimalism_vd + num_popart_vd
total_test = num_abstracticism_tt + num_baroque_tt + num_impressionism_tt + num_minimalism_tt + num_popart_tt
print('total training datatset: ', total_train)
print('total validation dataset: ', total_valid)
print('total test dataset: ', total_test)

datagen = ImageDataGenerator(rescale = 1./255)
batch_size = 32
epochs = 20

def extract_features(directory, sample_count, shuffle_value):
  features = np.zeros(shape=(sample_count, 6, 6, 512))
  labels = np.zeros(shape=(sample_count, 5)) 
  generator = datagen.flow_from_directory(directory, target_size = (200,200), 
                                          batch_size = batch_size, class_mode = 'categorical', 
                                          shuffle = shuffle_value)
  i = 0
  for inputs_batch, labels_batch in generator:
      features_batch = conv_base.predict(inputs_batch)
      features[i * batch_size : (i + 1) * batch_size] = features_batch
      labels[i * batch_size : (i + 1) * batch_size] = labels_batch
      i+=1
      if i * batch_size >= sample_count:
        break
  return features, labels, generator

train_features, train_labels, train_generator = extract_features(train_dir, total_train, True)
#validation_features, validation_labels, validation_generator = extract_features(validation_dir, total_valid, False)
test_features, test_labels, test_generator = extract_features(test_dir, total_test, False)

train_features = np.reshape(train_features, (total_train, 6 * 6 * 512))
print(train_features.shape)
print(train_labels.shape)

#validation_features = np.reshape(validation_features, (total_valid, 6 * 6 * 512))
#print(validation_features.shape)

test_features = np.reshape(test_features, (total_test, 6 * 6 * 512))
print(test_features.shape)

from keras import models
from keras import layers
from keras import optimizers

model = models.Sequential()
model.add(layers.Dense(512, activation = 'relu', input_dim = 6*6*512))
model.add(layers.Dropout(0.5))
model.add(layers.Dense(5, activation='softmax'))

model.compile(optimizer=optimizers.Adam(),
              loss='categorical_crossentropy',
              metrics=['accuracy'])

model.summary()

history = model.fit(train_features, train_labels, epochs = epochs,
                    batch_size= batch_size) #,
                    #validation_data = (validation_features, validation_labels))

acc = history.history['accuracy']
val_acc = history.history['val_accuracy']

loss=history.history['loss']
val_loss=history.history['val_loss']

epochs_range = range(epochs)
#epochs_range = range(1, len(loss) + 1)

plt.figure(figsize=(8, 8))
plt.subplot(1, 2, 1)

plt.plot(epochs_range, acc, label='Training Accuracy')
plt.plot(epochs_range, val_acc, label='Testing Accuracy')
plt.legend(loc='lower right')
plt.title('Training and Testing Accuracy')

plt.subplot(1, 2, 2)
plt.plot(epochs_range, loss, label='Training Loss')
plt.plot(epochs_range, val_loss, label='Testing Loss')
plt.legend(loc='upper right')
plt.title('Training and Testing Loss')
plt.show()

test_loss, test_acc = model.evaluate(test_features, test_labels)
print(test_acc)

from sklearn.metrics import classification_report, confusion_matrix
predictions = model.predict_classes(test_features)
print(predictions.size)
#y_pred = np.argmax(predictions, axis=1)
y_pred = predictions
print('Confusion Matrix')
#print(test_generator.classes)
cm = confusion_matrix(test_generator.classes, y_pred)
print(cm)
print('Classification Report')
 
print(classification_report(test_generator.classes, y_pred, target_names=CLASSES_NAMES))

def plot_confusion_matrix(cm, classes, normalize=False, title='Confusion Matrix', cmap=plt.cm.Greens):
  if normalize:
    cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]
    cm = cm*100
    print('\nNormalized Confusion Matrix')
  else: 
    print('\nConfusion Matrix, without Normalization')
   
  print(cm)
  print()

  plt.imshow(cm, interpolation='nearest', cmap=cmap)
  plt.title(title)
  plt.colorbar()
  tick_marks = np.arange(len(classes))
  plt.xticks(tick_marks, classes, rotation=90)
  plt.yticks(tick_marks, classes)


  fmt = '.0f' if normalize else 'd'
  thresh = cm.max()/2.
  for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):
     plt.text(j, i, format(cm[i, j], fmt),
               horizontalalignment="center",
               color="white" if cm[i, j] > thresh else "black")
  plt.tight_layout()
  plt.ylabel('True label')
  plt.xlabel('Predicted label')
  plt.show()

from sklearn.metrics import confusion_matrix
import itertools

y_pred = predictions

cnf_matrix = confusion_matrix(test_generator.classes, y_pred)
np.set_printoptions(precision=2)

plt.figure()
plot_confusion_matrix(cnf_matrix, classes=CLASSES_NAMES, title ='Confusion Matrix without Normalization')

valid_filenames = validation_generator.filenames

valid_ground_truth = validation_generator.classes

val_label2index = validation_generator.class_indices

# getting the mapping from class index to class label
val_idx2label = dict((v,k) for k,v in val_label2index.items())

val_predictions = model.predict_classes(validation_features)
valid_prob = model.predict(validation_features)

val_errors = np.where(val_predictions != valid_ground_truth)[0]
print("No of error = {}/{}".format(len(val_errors), total_valid))

test_filenames = test_generator.filenames
test_ground_truth = test_generator.classes
test_label2index = test_generator.class_indices
test_idx2label = dict((v, k) for k, v in test_label2index.items())

test_predictions = model.predict_classes(test_features)
test_prob = model.predict(test_features)

test_errors = np.where(test_predictions != test_ground_truth)[0]
print("No of error = {}/{}".format(len(test_errors), total_test))
print(test_errors)

test_correct = np.where(test_predictions == test_ground_truth)[0]
print("Correct Prediction = {}/{}".format(len(test_correct), total_test))
print(test_correct)

from random import seed
from random import randint

seed(1)
numnum = len(test_correct) / len(CLASSES_NAMES)
#print(numnum)

correct_path_lists = []
for j in range(len(CLASSES_NAMES)):
  print(j)
  for _ in range(3):
    numnum = int(numnum)
    print(str(numnum*j) + " ~ " + str(numnum*(j+1)))
    i = randint((numnum*j)+1, (numnum*(j+1)))
    print(i)
    pred_class = np.argmax(test_prob[test_correct[i]])
    #print(pred_class)
    pred_label = test_idx2label[pred_class]
    #print(pred_label)

    true_label = test_filenames[test_correct[i]].split('/')[0]
    #print(true_label)
    #print('True label : {}, Prediction : {}, confidence : {:.3f}'.format(
      #test_filenames[test_correct[i]].split('/')[0],
      #pred_label,
      #test_prob[test_correct[i]][pred_class]))
  

    #original = load_img('{}/{}'.format(test_dir, test_filenames[test_correct[i]]))
    original_path = ('{}/{}'.format(test_dir, test_filenames[test_correct[i]]))
  
    img_data = [true_label, pred_label, original_path];
    correct_path_lists.append(img_data);
    #print("original path: " + original_path)
    #print(original)
  
  


  #plt.imshow(original)
  #plt.show()

print(correct_path_lists)

"""Which images were predicted wrongly in test datasets"""

error_path_lists = []
for i in range(len(test_errors)):
  pred_class = np.argmax(test_prob[test_errors[i]])
  print(pred_class)
  pred_label = test_idx2label[pred_class]
  print(pred_label)

  true_label = test_filenames[test_errors[i]].split('/')[0]
  print(true_label)
  print('True label : {}, Prediction : {}, confidence : {:.3f}'.format(
      test_filenames[test_errors[i]].split('/')[0],
      pred_label,
      test_prob[test_errors[i]][pred_class]))
  

  original = load_img('{}/{}'.format(test_dir, test_filenames[test_errors[i]]))
  original_path = ('{}/{}'.format(test_dir, test_filenames[test_errors[i]]))
  
  img_data = [true_label, pred_label, original_path];
  error_path_lists.append(img_data);
  print("original path: " + original_path)
  print(original)
  
  plt.imshow(original)
  plt.show()

print(error_path_lists)

print(error_path_lists)
print(len(error_path_lists))
print(error_path_lists[0][2])

print(correct_path_lists)

test_name = "testcase 2"
print(test_name)
print(test_acc)
print(CLASS_NAMES)
class_name_list = CLASSES_NAMES
print(class_name_list)
print(class_name_list[0])

cmr = classification_report(test_generator.classes, y_pred, target_names=CLASSES_NAMES)
print(cmr)
print(type(cmr))
cm_report = classification_report(test_generator.classes, y_pred, target_names=CLASSES_NAMES, output_dict=True)
cm_label = ['precision', 'recall', 'f1-score', 'support']
print(cm_label)
print(len(cm_label))
print(cm_report)
print(len(class_name_list))

print(type(cm_report))
print("cm_report length: ", len(cm_report))

print(class_name_list[0])
print(cm_report[class_name_list[0]])
print(cm_report[class_name_list[0]]['f1-score'])
print(cm_report[class_name_list[0]][cm_label[2]])

print(type(cm_report[class_name_list[0]][cm_label[0]]));
#f1-score = float(cm_report[class_name_list[0]]['f1-score']);
#for i in range(len(cm_label))
f1_score = f"{cm_report[class_name_list[0]][cm_label[0]]:.2f}"
print(f1_score)

for idx in range(len(class_name_list)):
  #print(class_name_list[idx])
  for dex in range(len(cm_label) - 1):
    #print(cm_label[dex])
    cm_report[class_name_list[idx]][cm_label[dex]] = f"{cm_report[class_name_list[idx]][cm_label[dex]]:.2f}"

print(cm_report)

uuid = 'd0a1dfb8-69a5-48a4-952d-c6cde87a6aca';
uuid_1 = uuid.split('-')[0]
print(uuid_1)

cmlist = cm.tolist()
print(cmlist)
print(cmlist[0][0])

total_train = num_abstracticism_tr + num_baroque_tr + num_impressionism_tr + num_minimalism_tr + num_popart_tr
total_valid = num_abstracticism_vd + num_baroque_vd + num_impressionism_vd + num_minimalism_vd + num_popart_vd
total_test = num_abstracticism_tt + num_baroque_tt + num_impressionism_tt + num_minimalism_tt + num_popart_tt

import json 

results_json = {
    "test_name" : test_name,
    "test_accuracy" : test_acc,
    "classes" : class_name_list,
    "data_number" : {
        "train_data" : {
            "total_train" : total_train,
            "abstracticism" : num_abstracticism_tr,
            "baroque" : num_baroque_tr,
            "impressionism" : num_impressionism_tr,
            "minimalism" : num_minimalism_tr,
            "popart" : num_popart_tr
        },
        "test_data" : {
            "total_test" : total_test,
            "abstracticism" : num_abstracticism_tt,
            "baroque" : num_baroque_tt,
            "impressionism" : num_impressionism_tt,
            "minimalism" : num_minimalism_tt,
            "popart" : num_popart_tt
        }        
    },
    "confusion_report" : {
        class_name_list[0] : cm_report[class_name_list[0]],
        class_name_list[1] : cm_report[class_name_list[1]],
        class_name_list[2] : cm_report[class_name_list[2]],
        class_name_list[3] : cm_report[class_name_list[3]],
        class_name_list[4] : cm_report[class_name_list[4]]
    },
    "confusion_matrix" : cmlist,
    "test_images" : {
        "wrong_predicted_counts" : len(test_errors),
        "wrong_path" : error_path_lists,
        "sample_images_counts" : len(correct_path_lists),
        "sample_images_paths" : correct_path_lists
    }
}

json_results = json.dumps(results_json, indent = 4)
print(json_results)

sss = results_json["confusion_report"]["popart"]["precision"]
print(sss)

aaa = results_json["confusion_matrix"]
print(aaa)

with open('/content/gdrive/My Drive/testcase2/testcase2_result.json', 'w') as json_file:
  json.dump(results_json, json_file, indent = 4)

qwe = 0.9879283948 
qwe = f"{qwe:.3f}"

ff = float(wer)
print(qwe)
print(wer)
print(ff)

import json 

jsonex = {'param_id': 'art_classification', 'instance_label': ["impressionism#/static/art_classification/aaa.125.jpg", "impressionism#/static/art_classification/aaa.144.jpg", "abstracticism#/static/art_classification/aaa.448.jpg", "baroque#/static/art_classification/aaa.56.jpg", "impressionism#/static/art_classification/aaa.401.jpg", "minimalism#/static/art_classification/aaa.302.jpg", "baroque#/static/art_classification/aaa.292.jpg", "abstracticism#/static/art_classification/aaa.284.jpg", "impressionism#/static/art_classification/aaa.330.jpg", "popart#/static/art_classification/aaa.314.jpg"]}

json_ex = json.dumps(jsonex, indent = 4)
print(json_ex)

qqq = jsonex["instance_label"]
print(len(qqq))
print(qqq[1])

for i in range(len(qqq)):
  line_list = qqq[i].split('#')
  category = line_list[0]
  img_path = line_list[1]
  img_path_list = img_path.split('/')
  path_name = img_path_list[3]
  name_list = path_name.split('.')
  name_list[0] = category;
  name_list = '.'.join(name_list)
  print(category)
  print(img_path)
  print(path_name)
  print(name_list)
  print("--------------")
  img_path_list[3] = name_list
  img_path_list = '/'.join(img_path_list)
  line_list[1] = img_path_list
  qqq[i] = [line_list[0], line_list[1]]
  print(line_list)
  print("================")

print(qqq)
jsonex["instance_label"] = qqq
print(jsonex)
json_ex = json.dumps(jsonex, indent = 4)
print(json_ex)

import pathlib, os

root_directory = pathlib.Path('/static')
exercise1_dir = os.path.join(root_directory, 'exercise1')
#os.mkdir(exercise1_dir)

